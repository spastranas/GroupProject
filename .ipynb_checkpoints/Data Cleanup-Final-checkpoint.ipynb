{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup Final File for Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rafael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting country codes\n",
    "countrycodes_file = \"Resources/CountryCodesLookup.csv\"\n",
    "countrycodes = pd.read_csv(countrycodes_file, encoding=\"ISO-8859-1\")\n",
    "countrycodes = countrycodes.rename(columns={'COUNTRY':'country'})\n",
    "\n",
    "#Getting happiness index\n",
    "happiness_file = \"Resources/WorldHappinessReport.csv\"\n",
    "happiness = pd.read_csv(happiness_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "happiness2017 = happiness.loc[happiness['year']==2017,['country','Life Ladder']]\n",
    "print(happiness2017.head())\n",
    "\n",
    "#Merging both\n",
    "mymerge = pd.merge(countrycodes, happiness2017, how=\"left\", on=['country'])\n",
    "mymerge = mymerge.drop(['A3 (UN)','NUM (UN)','DIALING CODE','spotifyFlag'],axis=1)\n",
    "print(mymerge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking indicators and grabbing interesting data for analysis\n",
    "baseurl = \"http://api.worldbank.org/v2/country/\"\n",
    "year = \"2017\"\n",
    "\n",
    "def grabindicator(y):\n",
    "    if y == 0: #Mobile cellular subscriptions (per 100 people)\n",
    "        x = \"IT.CEL.SETS.P2\"\n",
    "    elif y == 1: #Individuals using the Internet (% of population)\n",
    "        x = \"IT.NET.USER.ZS\"\n",
    "    elif y == 2: # Population, female (% of total)\n",
    "        x = \"SP.POP.TOTL.FE.ZS\"\n",
    "    elif y == 3: # Unemployment, total (% of total labor force) (modeled ILO estimate)\n",
    "        x = \"SL.UEM.TOTL.ZS\"\n",
    "    else:\n",
    "        print(f'Indicator \"{y}\" not available')\n",
    "    return x\n",
    "\n",
    "temp = []\n",
    "mobilephones = []\n",
    "internet = []\n",
    "femalepopulation = []\n",
    "unemployment = []\n",
    "\n",
    "countryfound = []\n",
    "\n",
    "def lists(indicatorcod, x, lock, errorfree):\n",
    "\n",
    "    try:   \n",
    "        if indicatorcod == 0: #Mobile cellular subscriptions (per 100 people)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            mobilephones.append(temp['value'])\n",
    "    \n",
    "        elif indicatorcod == 1: #Individuals using the Internet (% of population)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            internet.append(temp['value'])         \n",
    "\n",
    "        elif indicatorcod == 2: # # Population, female (% of total)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            femalepopulation.append(temp['value'])\n",
    "\n",
    "        elif indicatorcod == 3: # Unemployment, total (% of total labor force) (modeled ILO estimate)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            print (temp)\n",
    "            print(temp['value'])\n",
    "            unemployment.append(temp['value'])       \n",
    "        \n",
    "        else:\n",
    "            print(\"*** Error on function 'lists' ***\")\n",
    "\n",
    "        \n",
    "        if lock != 1 and errorfree == 1 and indicatorcod <1:\n",
    "                countryfound.append(pais)\n",
    "                lock = 1\n",
    "        \n",
    "    except TypeError:\n",
    "        print(f'Error: Country Code \"{countrycode}\" not found')\n",
    "\n",
    "\n",
    "\n",
    "for i in range (4):\n",
    "    indicatorcode = grabindicator(i)\n",
    "    indicatorcounter = int(i)\n",
    "    lock = 0\n",
    "\n",
    "    for code,pais in zip(mymerge['A2 (ISO)'], mymerge['country']):        \n",
    "        countrycode = code\n",
    "        print(f'Iteration {indicatorcounter}')\n",
    "        print(pais)\n",
    "        query_url = f\"{baseurl}{countrycode}/indicator/{indicatorcode}?date={year}&format=json\"\n",
    "        print (query_url)\n",
    "        response = requests.get(query_url).json()\n",
    "        print(f'response is {response}\\n')\n",
    "        \n",
    "        if len(response) < 2:\n",
    "            print(f'response for {countrycode} is invalid\\n')\n",
    "            errorfree = 0\n",
    "        elif response[1] is None:\n",
    "            print(f'response for {countrycode} is None \\n')\n",
    "            errorfree = 0\n",
    "        else:\n",
    "            errorfree = 1\n",
    "            lists(indicatorcounter, response, lock, errorfree)\n",
    "                                  \n",
    "\n",
    "print(\"\\n***********all data was collected via the API\")\n",
    "\n",
    "countryfound1 = pd.DataFrame(countryfound)\n",
    "\n",
    "#Compiling grabbed data from API Calls into one data frame\n",
    "\n",
    "mymerge_dict = {\n",
    "    \"Country\": countryfound,\n",
    "    \"Individuals using the Internet (% of population)\": internet,\n",
    "    \"% Female Total Population\": femalepopulation,\n",
    "    \"Total Unemployment\": unemployment,\n",
    "    \"Mobile Phones (per 100 people)\": mobilephones}\n",
    "\n",
    "mymerge_data = pd.DataFrame(mymerge_dict)\n",
    "\n",
    "womenmajority = []\n",
    "label1 =[]\n",
    "\n",
    "\n",
    "for y in mymerge_data['% Female Total Population']:\n",
    "   \n",
    "    if y == 50:\n",
    "        womenmajority.append('turquoise')\n",
    "        label1.append(\"Country without gender majority\")\n",
    "    elif y < 50:\n",
    "        womenmajority.append('yellow')\n",
    "        label1.append(\"Country with male majority\")\n",
    "    else:\n",
    "        womenmajority.append('red')\n",
    "        label1.append(\"Country with female majority\")\n",
    " \n",
    "\n",
    "womenmajority1 = pd.DataFrame(womenmajority)\n",
    "womenmajority1 = womenmajority1.rename(columns={0:'Plot Color % Female population'})\n",
    "\n",
    "labelGender = pd.DataFrame(label1)\n",
    "labelGender = labelGender.rename(columns={0:'Female majority label'})\n",
    "\n",
    "mymerge_data = pd.merge(mymerge_data, womenmajority1, how=\"outer\", left_index=True,right_index=True)\n",
    "mymerge_data = pd.merge(mymerge_data, labelGender, how=\"outer\", left_index=True,right_index=True)\n",
    "\n",
    "\n",
    "#Compiling grabbed data from API Calls into one data frame\n",
    "\n",
    "mymerge_data = pd.merge(mymerge, mymerge_data, how=\"outer\", left_on=['country'],right_on=['Country'])\n",
    "mymerge_data = mymerge_data.drop(['Country'],axis=1)\n",
    "mymerge_data = mymerge_data.loc[mymerge_data['Total Unemployment'] > 0,\n",
    "                                ['country','A2 (ISO)','Life Ladder','Total Unemployment','Individuals using the Internet (% of population)',\n",
    "                                 '% Female Total Population','Mobile Phones (per 100 people)',\n",
    "                                 'Plot Color % Female population','Female majority label']]\n",
    "mymerge_data = mymerge_data.loc[mymerge_data['Life Ladder'] > 0,\n",
    "                                ['country','A2 (ISO)','Life Ladder','Total Unemployment','Individuals using the Internet (% of population)',\n",
    "                                 '% Female Total Population','Mobile Phones (per 100 people)',\n",
    "                                 'Plot Color % Female population','Female majority label']]\n",
    "\n",
    "mymerge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving all data to disk/file\n",
    "outputfileCSV = open('Outputs/TotalUnemploymentVsHappinessPlot-Rafael.csv', 'w+' )\n",
    "outputfile1 = mymerge_data.to_csv(index=True)\n",
    "outputfileCSV.write(outputfile1)\n",
    "outputfileCSV.close()\n",
    "\n",
    "\n",
    "#Plotting 1\n",
    "y_axis1 = mymerge_data['Life Ladder']       #use this for all plots\n",
    "x_axis1 = mymerge_data['Total Unemployment']\n",
    "\n",
    "Unemployment, ax = plt.subplots()\n",
    "#Unemployment = plt.scatter(x_axis1,y_axis1,marker='o', alpha=0.75, color = mymerge_data['Plot Color % Female population'],edgecolor =\"black\", label = '% Total Unemployment')\n",
    "Unemployment = plt.scatter(x_axis1,y_axis1,marker='o', alpha=0.75, color = 'orangered',edgecolor =\"black\", label = '% Total Unemployment')\n",
    "\n",
    "# Set line for regression \n",
    "(slope, intercept,r_value, p_value, _) = scipy.stats.linregress(x_axis1, y_axis1)\n",
    "fit = slope * x_axis1 + intercept\n",
    "\n",
    "\n",
    "# Print R-Sqr and P-Value\n",
    "print(f\"r-squared: {r_value**2}, p-value: {p_value}\")\n",
    "# Plot line\n",
    "ax.plot(x_axis1, fit, 'b--')\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "plt.title(\"Unemployment x Happiness\", fontsize=10, fontweight=\"bold\")\n",
    "plt.ylabel(\"Happiness index\")\n",
    "plt.xlabel(\"Unemployment\")\n",
    "\n",
    "#Save plot to file\n",
    "Unemployment,plt.savefig(\"Graphs/TotalUnemploymentVsHappinessPlot-RafaelSantos.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Plotting 2\n",
    "y_axis1 = mymerge_data['Life Ladder']       #use this for all plots\n",
    "x_axis2 = mymerge_data['% Female Total Population']\n",
    "\n",
    "FemalePopulation, ax = plt.subplots()\n",
    "#FemalePopulation = plt.scatter(x_axis2,y_axis1,marker='o', alpha=0.75, color = mymerge_data['Plot Color % Female population'],edgecolor =\"black\", label = '% Female Total Population')\n",
    "FemalePopulation = plt.scatter(x_axis2,y_axis1,marker='o', alpha=0.75, color = 'lime',edgecolor =\"black\", label = '% Female Total Population')\n",
    "\n",
    "# Set line for regression \n",
    "(slope, intercept,r_value, p_value, _) = scipy.stats.linregress(x_axis2, y_axis1)\n",
    "fit2 = slope * x_axis2 + intercept\n",
    "\n",
    "\n",
    "# Print R-Sqr and P-Value\n",
    "print(f\"r-squared: {r_value**2}, p-value: {p_value}\")\n",
    "# Plot line\n",
    "ax.plot(x_axis2, fit2, 'b--')\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "plt.title(\"% Female Total Population x Happiness\", fontsize=10, fontweight=\"bold\")\n",
    "plt.ylabel(\"Happiness index\")\n",
    "plt.xlabel(\"% Female Total Population\")\n",
    "\n",
    "#Save plot to file\n",
    "FemalePopulation,plt.savefig(\"Graphs/PercentageFemaleTotalPopulationVsHappinessPlot-RafaelSantos.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Plotting 3\n",
    "\n",
    "mymerge_dataInternet = mymerge_data.loc[mymerge_data['Individuals using the Internet (% of population)'] > 0,\n",
    "                                ['country','A2 (ISO)','Life Ladder','Total Unemployment','Individuals using the Internet (% of population)',\n",
    "                                 '% Female Total Population','Mobile Phones (per 100 people)',\n",
    "                                 'Plot Color % Female population','Female majority label']]\n",
    "\n",
    "\n",
    "\n",
    "y_axis1 = mymerge_dataInternet['Life Ladder']       #use this for all plots\n",
    "x_axis3 = mymerge_dataInternet['Individuals using the Internet (% of population)']\n",
    "\n",
    "Internet, ax = plt.subplots()\n",
    "#Internet = plt.scatter(x_axis3,y_axis1,marker='o', alpha=0.75, color = mymerge_data['Plot Color % Female population'],edgecolor =\"black\", label = 'Individuals using the Internet (% of population)')\n",
    "Internet = plt.scatter(x_axis3,y_axis1,marker='o', alpha=0.75, color = \"gold\",edgecolor =\"black\", label = 'Individuals using the Internet (% of population)')\n",
    "\n",
    "# Set line for regression \n",
    "(slope, intercept,r_value, p_value, _) = scipy.stats.linregress(x_axis3, y_axis1)\n",
    "fit3 = slope * x_axis3 + intercept\n",
    "\n",
    "\n",
    "# Print R-Sqr and P-Value\n",
    "print(f\"r-squared: {r_value**2}, p-value: {p_value}\")\n",
    "# Plot line\n",
    "ax.plot(x_axis3, fit3, 'b--')\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "plt.title(\"Individuals using the Internet (% of population) x Happiness\", fontsize=10, fontweight=\"bold\")\n",
    "plt.ylabel(\"Happiness index\")\n",
    "plt.xlabel(\"Individuals using the Internet (% of population)\")\n",
    "\n",
    "#Save plot to file\n",
    "Internet,plt.savefig(\"Graphs/IndividualsUsingInternetVsHappinessPlot-RafaelSantos.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Plotting 4\n",
    "mymerge_dataMobile = mymerge_data.loc[mymerge_data['Mobile Phones (per 100 people)'] > 0,\n",
    "                                ['country','A2 (ISO)','Life Ladder','Total Unemployment','Individuals using the Internet (% of population)',\n",
    "                                 '% Female Total Population','Mobile Phones (per 100 people)',\n",
    "                                 'Plot Color % Female population','Female majority label']]\n",
    "\n",
    "\n",
    "y_axis1 = mymerge_dataMobile['Life Ladder']       #use this for all plots\n",
    "x_axis4 = mymerge_dataMobile['Mobile Phones (per 100 people)']\n",
    "\n",
    "MobilePhones100ppl, ax = plt.subplots()\n",
    "#MobilePhones100ppl = plt.scatter(x_axis4,y_axis1,marker='o', alpha=0.75, color = mymerge_dataMobile['Plot Color % Female population'],edgecolor =\"black\", label = 'Mobile Phones (per 100 people)')\n",
    "MobilePhones100ppl = plt.scatter(x_axis4,y_axis1,marker='o', alpha=0.75, color = 'tomato',edgecolor =\"black\", label = 'Mobile Phones (per 100 people)')\n",
    "\n",
    "# Set line for regression \n",
    "(slope, intercept,r_value, p_value, _) = scipy.stats.linregress(x_axis4, y_axis1)\n",
    "fit4 = slope * x_axis4 + intercept\n",
    "\n",
    "\n",
    "# Print R-Sqr and P-Value\n",
    "print(f\"r-squared: {r_value**2}, p-value: {p_value}\")\n",
    "# Plot line\n",
    "ax.plot(x_axis4, fit4, 'b--')\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "plt.title(\"Mobile Phones (per 100 people) x Happiness\", fontsize=10, fontweight=\"bold\")\n",
    "plt.ylabel(\"Happiness index\")\n",
    "plt.xlabel(\"Mobile Phones (per 100 people)\")\n",
    "\n",
    "#Save plot to file\n",
    "MobilePhones100ppl,plt.savefig(\"Graphs/MobilePhones100pplVsHappinessPlot-RafaelSantos.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arghavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Happiness DF\n",
    "Happiness =  pd.read_csv('Resources/WorldHappinessReport.csv')\n",
    "Happiness_New = Happiness.drop(columns=['Delivery Quality', 'Democratic Quality', \n",
    "                                        'Standard deviation of ladder by country-year',\n",
    "                                        'Standard deviation/Mean of ladder by country-year',\n",
    "                                        'GINI index (World Bank estimate)', 'GINI index (World Bank estimate), average 2000-15',\n",
    "                                        'gini of household income reported in Gallup, by wp5-year'])\n",
    "\n",
    "Happiness_Updated = Happiness_New.loc[Happiness_New[\"year\"]==2016,:]\n",
    "Happiness_Olympics = Happiness_Updated.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Olympics DF\n",
    "CSV_athletes = pd.read_csv(\"Resources/120-years-of-olympic-history-athletes-and-results/athlete_events.csv\")\n",
    "CSV_countries =  pd.read_csv(\"Resources/120-years-of-olympic-history-athletes-and-results/noc_regions.csv\")\n",
    "\n",
    "#Cleaning Athletes DF\n",
    "CSV_athletes = CSV_athletes.drop(columns=['Season', 'City', 'Height', 'Weight'])\n",
    "CSV_athletes = CSV_athletes.loc[CSV_athletes[\"Year\"]==2016,:]\n",
    "CSV_athletes_updated = CSV_athletes.fillna(\"none\")\n",
    "\n",
    "#Merging Athletes and Country DF\n",
    "merged_athletes = pd.merge(CSV_athletes_updated, CSV_countries, on = \"NOC\", how = \"left\")\n",
    "merged_athletes = merged_athletes.rename(columns= {\"region\" : \"country\"})\n",
    "\n",
    "#Getting Number of Atheletes\n",
    "merged_athletes1 = merged_athletes.groupby(merged_athletes[\"country\"])\n",
    "Final_athletes = merged_athletes1[\"Name\"].count()\n",
    "Final_df = pd.DataFrame(Final_athletes)\n",
    "Final_df = Final_df.rename(columns= {\"Name\" : \"Number of Athletes\"})\n",
    "\n",
    "# Changin USA to United States so it merges with Happiness DF\n",
    "Final_df = Final_df.rename(index={\"USA\":'United States'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Final DF\n",
    "Athlete_Happiness = pd.merge(Final_df, Happiness_Olympics, on = \"country\")\n",
    "Athlete_Happiness.to_csv(\"Outputs/Athlete_Happiness.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shayan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happiness_df = pd.read_csv(\"Resources/WorldHappinessReport.csv\")\n",
    "tourism_df = pd.read_csv(\"Resources/Tourism.csv\", skiprows=3)\n",
    "happiness17_df = happiness_df.loc[(happiness_df[\"year\"] == 2017)]\n",
    "happiness_score = happiness17_df[[\"country\", \"Life Ladder\"]]\n",
    "happiness_score.columns = [\"Country Name\", \"Happines Score\"]\n",
    "tourism_number = tourism_df[[\"Country Name\", \"2017\"]]\n",
    "tourism_number = tourism_number.fillna(0)\n",
    "merge_table = pd.merge(happiness_score, tourism_number, on = \"Country Name\")\n",
    "merge_table.to_csv(\"Outputs/Tourism_Happiness.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mariana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe from a file using pandas\n",
    "file = 'Resources/Capitals.csv'\n",
    "# read the CSV in pandas\n",
    "weather = pd.read_csv(file, encoding=\"ISO-8859-1\")\n",
    "weather.reset_index(inplace=True)\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up additional columns to hold information\n",
    "weather['Temperature'] = \"\"\n",
    "\n",
    "base_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "\n",
    "#print(response['main']['temp'])\n",
    "# use iterrows to iterate through pandas dataframe\n",
    "for index, row in weather.iterrows():\n",
    "\n",
    "    # iterate thru each row of the file\n",
    "    city = row['Cities']\n",
    "    url = base_url + \"appid=\" + \"082ff2cde1d396b2b896b2335daad199\" + \"&q=\" + city +\"&units=imperial\"\n",
    "\n",
    "# assemble url and make API request\n",
    "    response = requests.get(url).json()\n",
    "  \n",
    "    #update the dataframe \n",
    "    try:\n",
    "        weather.loc[index, 'Temperature'] = response['main']['temp']\n",
    "        \n",
    "    except (KeyError, IndexError):\n",
    "        print(\"Missing field/result... skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. get top songs by country choosing one random day a month for the whole year of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe from a file using pandas\n",
    "file = 'Resources/CountryCodesLookup.csv'\n",
    "#upload country lookup\n",
    "Countries=pd.read_csv(file,encoding=\"ISO-8859-1\")\n",
    "#upload dates to look for top songs\n",
    "spDates= pd.read_csv('Resources/DatesForSpotifyTopSongs.csv')\n",
    "Countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by countries in spotify\n",
    "spCountries = Countries.loc[Countries[\"spotifyFlag\"] == 1,[\"COUNTRY\",\"A2 (ISO)\"]]\n",
    "\n",
    "# make a list of countries by dates to get their top 200 songs\n",
    "#cross join\n",
    "spCountries[\"Key\"]=1\n",
    "spDates[\"Key\"]=1\n",
    "spCountries[\"Processed\"]=0\n",
    "CountryDate = pd.merge(spCountries, spDates, on=\"Key\").reset_index(drop=True)\n",
    "#.head(1)\n",
    "#CountryDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract top songs by country in 2017. \n",
    "# rows get marked as processed. If the script failes, at re-start, it will exclude processed/failed rows.\n",
    "# this needs to be restarted as many times as it fails.\n",
    "\n",
    "spCountriesToProcess = CountryDate.loc[(CountryDate[\"Processed\"] == 0) & (CountryDate[\"COUNTRY\"]!='AD' ),:]\n",
    "\n",
    "\n",
    "from fycharts import SpotifyCharts \n",
    "api = SpotifyCharts.SpotifyCharts()\n",
    "\n",
    "\n",
    "# use iterrows to iterate through pandas dataframe\n",
    "for index, row in spCountriesToProcess.iterrows():\n",
    "\n",
    "    # iterate thru each row of the file\n",
    "    countryCode = str.lower(row['A2 (ISO)'])\n",
    "    startDate=row[\"startDate\"]\n",
    "    EndDate=row[\"EndDate\"]\n",
    "    \n",
    "    #get data\n",
    "    print(startDate)  \n",
    "    print (countryCode)\n",
    "    CountryDate.loc[index, 'Processed'] = 1\n",
    "   \n",
    "       \n",
    "    api.top200Daily(output_file = 'Outputs/Spotify2017Top.csv', start=startDate, end=EndDate, region=countryCode)\n",
    "#viral50Daily    \n",
    "#top200Weekly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Query spotify API. Find the songs attributes.  Classify all songs found and saved in the Soptify2017Top.cvs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='Outputs/Spotify2017Top1.csv'\n",
    "TopSpotify=pd.read_csv(file,encoding=\"ISO-8859-1\")\n",
    "TopSpotify.columns\n",
    "TopSpotify[\"uri\"]='spotify:track:'+TopSpotify[\"id\"]\n",
    "#New columns\n",
    "TopSpotify[\"happiness\"]=''\n",
    "TopSpotify[\"energy\"]=''\n",
    "TopSpotify[\"danceability\"]=''\n",
    "TopSpotify[\"loudness\"]=''\n",
    "TopSpotify[\"speechiness\"]=''\n",
    "TopSpotify[\"instrumentalness\"]=''\n",
    "\n",
    "\n",
    "TopSpotify.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spotipy\n",
    "\n",
    "client_id='hiddenCode'\n",
    "client_secret='HiddenCode'\n",
    "\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id,client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "\n",
    "# use iterrows to iterate through pandas dataframe\n",
    "for index, row in TopSpotify.iterrows():\n",
    "\n",
    "    # iterate thru each row of the file\n",
    "    tid = row['uri']\n",
    "    try:\n",
    "        fearure = sp.audio_features(tid)\n",
    "        happiness = fearure[0][\"valence\"]\n",
    "        energy = fearure[0][\"energy\"]\n",
    "        danceability=fearure[0][\"danceability\"]\n",
    "        loudness=fearure[0][\"loudness\"]\n",
    "        speechiness=fearure[0][\"speechiness\"]\n",
    "        instrumentalness=fearure[0][\"instrumentalness\"]\n",
    "\n",
    "    #write back to data frame\n",
    "               \n",
    "        TopSpotify.loc[index, 'happiness'] = happiness\n",
    "        TopSpotify.loc[index, 'energy'] = energy\n",
    "        TopSpotify.loc[index, 'danceability'] = danceability\n",
    "        TopSpotify.loc[index, 'loudness'] = loudness\n",
    "        TopSpotify.loc[index, 'speechiness'] = speechiness\n",
    "        TopSpotify.loc[index, 'instrumentalness'] = instrumentalness\n",
    "        \n",
    "\n",
    "    except (KeyError, IndexError, NoneType):\n",
    "        print(tid)\n",
    "        print(\"Missing field/result... skipping.\")\n",
    "TopSpotify.to_csv(\"Outputs/SpotifyTop2017Final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
