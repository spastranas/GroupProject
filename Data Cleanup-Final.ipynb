{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rafael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting country codes\n",
    "countrycodes_file = \"Resources/CountryCodesLookup.csv\"\n",
    "countrycodes = pd.read_csv(countrycodes_file, encoding=\"ISO-8859-1\")\n",
    "countrycodes = countrycodes.rename(columns={'COUNTRY':'country'})\n",
    "\n",
    "#Getting happiness index\n",
    "happiness_file = \"Resources/WorldHappinessReport.csv\"\n",
    "happiness = pd.read_csv(happiness_file, encoding=\"ISO-8859-1\")\n",
    "\n",
    "happiness2017 = happiness.loc[happiness['year']==2017,['country','Life Ladder']]\n",
    "print(happiness2017.head())\n",
    "\n",
    "#Merging both\n",
    "mymerge = pd.merge(countrycodes, happiness2017, how=\"left\", on=['country'])\n",
    "mymerge = mymerge.drop(['A3 (UN)','NUM (UN)','DIALING CODE','spotifyFlag'],axis=1)\n",
    "print(mymerge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking indicators and grabbing interesting data for analysis\n",
    "baseurl = \"http://api.worldbank.org/v2/country/\"\n",
    "year = \"2017\"\n",
    "\n",
    "def grabindicator(y):\n",
    "    if y == 0: #Surface area (sq.km)\n",
    "        x = \"AG.SRF.TOTL.K2\"\n",
    "    elif y == 1: #Population, total\n",
    "        x = \"SP.POP.TOTL\"\n",
    "    elif y == 2: # Labor Force\n",
    "        x = \"SL.TLF.TOTL.IN\"\n",
    "    elif y == 3: # Unemployment, total (% of total labor force) (modeled ILO estimate)\n",
    "        x = \"SL.UEM.TOTL.ZS\"\n",
    "    else:\n",
    "        print(f'Indicator \"{y}\" not available')\n",
    "    return x\n",
    "\n",
    "temp = []\n",
    "surfacearea = []\n",
    "population = []\n",
    "laborforce = []\n",
    "unemployment = []\n",
    "\n",
    "countryfound = []\n",
    "\n",
    "def lists(indicatorcod, x, lock, errorfree):\n",
    "\n",
    "    try:   \n",
    "        if indicatorcod == 0: #Surface area (sq.km)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            surfacearea.append(temp['value'])\n",
    "    \n",
    "        elif indicatorcod == 1: #Population, total\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            population.append(temp['value'])         \n",
    "\n",
    "        elif indicatorcod == 2: # Labor Force\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            laborforce.append(temp['value'])\n",
    "\n",
    "        elif indicatorcod == 3: # Unemployment, total (% of total labor force) (modeled ILO estimate)\n",
    "            temp = x[1]\n",
    "            temp = temp[0]\n",
    "            print (temp)\n",
    "            print(temp['value'])\n",
    "            unemployment.append(temp['value'])       \n",
    "        \n",
    "        else:\n",
    "            print(\"*** Error on function 'lists' ***\")\n",
    "\n",
    "        \n",
    "        if lock != 1 and errorfree == 1 and indicatorcod <1:\n",
    "                countryfound.append(pais)\n",
    "                lock = 1\n",
    "        \n",
    "    except TypeError:\n",
    "        print(f'Error: Country Code \"{countrycode}\" not found')\n",
    "\n",
    "\n",
    "\n",
    "for i in range (4):\n",
    "    indicatorcode = grabindicator(i)\n",
    "    indicatorcounter = int(i)\n",
    "    lock = 0\n",
    "\n",
    "    for code,pais in zip(mymerge['A2 (ISO)'], mymerge['country']):        \n",
    "        countrycode = code\n",
    "        print(pais)        \n",
    "        print(indicatorcounter)\n",
    "        query_url = f\"{baseurl}{countrycode}/indicator/{indicatorcode}?date={year}&format=json\"\n",
    "        print (query_url)\n",
    "        response = requests.get(query_url).json()\n",
    "        print(f'response is {response}\\n')\n",
    "        \n",
    "        if len(response) < 2:\n",
    "            print(f'response for {countrycode} is invalid\\n')\n",
    "            errorfree = 0\n",
    "        elif response[1] is None:\n",
    "            print(f'response for {countrycode} is None \\n')\n",
    "            errorfree = 0\n",
    "        else:\n",
    "            errorfree = 1\n",
    "            lists(indicatorcounter, response, lock, errorfree)\n",
    "                                  \n",
    "\n",
    "print(\"\\n***********all data was collected via the API\")\n",
    "\n",
    "countryfound1 = pd.DataFrame(countryfound)\n",
    "\n",
    "\n",
    "#Compiling grabbed data from API Calls into one data frame\n",
    "mymerge_dict = {\n",
    "    \"Country\": countryfound,\n",
    "    \"Surface Area\": surfacearea,\n",
    "    \"Total Population\": population,\n",
    "    \"Labor Force\": laborforce,\n",
    "    \"Total Unemployment\": unemployment}\n",
    "mymerge_data = pd.DataFrame(mymerge_dict)\n",
    "\n",
    "mymerge_data = pd.merge(mymerge, mymerge_data, how=\"left\", left_on=['country'],right_on=['Country'])\n",
    "mymerge_data = mymerge_data.drop(['Country'],axis=1)\n",
    "\n",
    "#Saving all data to disk/file\n",
    "outputfileCSV = open('Outputs/TotalUnemploymentVsHappinessPlot-Rafael.csv', 'w+' )\n",
    "outputfile1 = mymerge_data.to_csv(index=True)\n",
    "outputfileCSV.write(outputfile1)\n",
    "outputfileCSV.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "y_axis1 = mymerge_data['Life Ladder']       #use this for all plots\n",
    "x_axis1 = mymerge_data['Total Unemployment']\n",
    "\n",
    "Unemployment, ax = plt.subplots()\n",
    "Unemployment = plt.scatter(x_axis1,y_axis1,marker='s', alpha=0.75, color = \"yellow\",edgecolor =\"black\", label = '% Total Unemployment')\n",
    "\n",
    "# Set line for regression \n",
    "##(slope, intercept, _, _, _) = sci.stats.linregress(x_axis1, y_axis1)\n",
    "##fit = slope * x_axis1 + intercept\n",
    "\n",
    "# Plot line\n",
    "##ax.plot(x_axis1, fit, 'b--')\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.title(\"Unemployment vs Happiness\")\n",
    "plt.ylabel(\"Happiness index\")\n",
    "plt.xlabel(\"Unemployment\")\n",
    "\n",
    "#Save plot to file\n",
    "Unemployment,plt.savefig(\"Graphs/TotalUnemploymentVsHappinessPlot-RafaelSantos.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arghavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Happiness DF\n",
    "Happiness =  pd.read_csv('Resources/WorldHappinessReport.csv')\n",
    "Happiness_New = Happiness.drop(columns=['Delivery Quality', 'Democratic Quality', \n",
    "                                        'Standard deviation of ladder by country-year',\n",
    "                                        'Standard deviation/Mean of ladder by country-year',\n",
    "                                        'GINI index (World Bank estimate)', 'GINI index (World Bank estimate), average 2000-15',\n",
    "                                        'gini of household income reported in Gallup, by wp5-year'])\n",
    "\n",
    "Happiness_Updated = Happiness_New.loc[Happiness_New[\"year\"]==2016,:]\n",
    "Happiness_Olympics = Happiness_Updated.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Olympics DF\n",
    "CSV_athletes = pd.read_csv(\"Resources/120-years-of-olympic-history-athletes-and-results/athlete_events.csv\")\n",
    "CSV_countries =  pd.read_csv(\"Resources/120-years-of-olympic-history-athletes-and-results/noc_regions.csv\")\n",
    "\n",
    "#Cleaning Athletes DF\n",
    "CSV_athletes = CSV_athletes.drop(columns=['Season', 'City', 'Height', 'Weight'])\n",
    "CSV_athletes = CSV_athletes.loc[CSV_athletes[\"Year\"]==2016,:]\n",
    "CSV_athletes_updated = CSV_athletes.fillna(\"none\")\n",
    "\n",
    "#Merging Athletes and Country DF\n",
    "merged_athletes = pd.merge(CSV_athletes_updated, CSV_countries, on = \"NOC\", how = \"left\")\n",
    "merged_athletes = merged_athletes.rename(columns= {\"region\" : \"country\"})\n",
    "\n",
    "#Getting Number of Atheletes\n",
    "merged_athletes1 = merged_athletes.groupby(merged_athletes[\"country\"])\n",
    "Final_athletes = merged_athletes1[\"Name\"].count()\n",
    "Final_df = pd.DataFrame(Final_athletes)\n",
    "Final_df = Final_df.rename(columns= {\"Name\" : \"Number of Athletes\"})\n",
    "\n",
    "# Changin USA to United States so it merges with Happiness DF\n",
    "Final_df = Final_df.rename(index={\"USA\":'United States'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Final DF\n",
    "Athlete_Happiness = pd.merge(Final_df, Happiness_Olympics, on = \"country\")\n",
    "Athlete_Happiness.to_csv(\"Outputs/Athlete_Happiness.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shayan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happiness_df = pd.read_csv(\"Resources/WorldHappinessReport.csv\")\n",
    "tourism_df = pd.read_csv(\"Resources/Tourism.csv\", skiprows=3)\n",
    "happiness17_df = happiness_df.loc[(happiness_df[\"year\"] == 2017)]\n",
    "happiness_score = happiness17_df[[\"country\", \"Life Ladder\"]]\n",
    "happiness_score.columns = [\"Country Name\", \"Happines Score\"]\n",
    "tourism_number = tourism_df[[\"Country Name\", \"2017\"]]\n",
    "tourism_number = tourism_number.fillna(0)\n",
    "merge_table = pd.merge(happiness_score, tourism_number, on = \"Country Name\")\n",
    "merge_table.to_csv(\"Outputs/Tourism_Happiness.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mariana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
